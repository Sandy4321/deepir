{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Inverse Regression with Yelp reviews\n",
    "\n",
    "In this note we'll use [gensim](http://radimrehurek.com/gensim/) to turn the Word2Vec machinery into a document classifier, as in [Document Classification by Inversion of Distributed Language Representations](http://arxiv.org/pdf/1504.07295v3) from ACL 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, download to the same directory as this note the data from the [Yelp recruiting contest](https://www.kaggle.com/c/yelp-recruiting) on [kaggle](https://www.kaggle.com/):\n",
    "* https://www.kaggle.com/c/yelp-recruiting/download/yelp_training_set.zip\n",
    "* https://www.kaggle.com/c/yelp-recruiting/download/yelp_test_set.zip\n",
    "\n",
    "You'll need to sign-up for kaggle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then unpack the data and grab the information we need.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use an incredibly simple parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "contractions = re.compile(r\"'|-|\\\"\")\n",
    "# all non alphanumeric\n",
    "symbols = re.compile(r'(\\W+)', re.U)\n",
    "# single character removal\n",
    "singles = re.compile(r'(\\s\\S\\s)', re.I|re.U)\n",
    "# separators (any whitespace)\n",
    "seps = re.compile(r'\\s+')\n",
    "\n",
    "# cleaner (order matters)\n",
    "def clean(text): \n",
    "    text = text.lower()\n",
    "    text = contractions.sub('', text)\n",
    "    text = symbols.sub(r' \\1 ', text)\n",
    "    text = singles.sub(' ', text)\n",
    "    text = seps.sub(' ', text)\n",
    "    return text\n",
    "\n",
    "# sentence splitter\n",
    "alteos = re.compile(r'([!\\?])')\n",
    "def sentences(l):\n",
    "    l = alteos.sub(r' \\1 .', l).rstrip(\"(\\.)*\\n\")\n",
    "    return l.split(\".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And put everything together in a review generator that provides tokenized sentences and the number of stars for every review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import json\n",
    "\n",
    "def YelpReviews(label):\n",
    "    with ZipFile(\"yelp_%s_set.zip\"%label, 'r') as zf:\n",
    "        with zf.open(\"yelp_%s_set/yelp_%s_set_review.json\"%(label,label)) as f:\n",
    "            for line in f:\n",
    "                rev = json.loads(line)\n",
    "                yield {'y':rev['stars'],\\\n",
    "                       'x':[clean(s) for s in sentences(rev['text'])]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [u'nice place big patio',\n",
       "  u' now offering live sketch comedy ',\n",
       "  u' wednesday november 17th see local troupe th sic sense in their 2nd annual holiday show ',\n",
       "  u' lighter snappier take on the holiday times',\n",
       "  u' not for the easily offended',\n",
       "  u' sketches include the scariest holloween costume the first thanksgiving and who shot santa claus ',\n",
       "  u' as well as the infectious song mama christmas'],\n",
       " 'y': 5}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YelpReviews(\"test\").next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, since the files are small we'll just read everything into in-memory lists.  It takes a minute ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229907 training reviews and 22956 test reviews\n"
     ]
    }
   ],
   "source": [
    "revtrain = list(YelpReviews(\"training\"))\n",
    "print len(revtrain), \"training reviews\"\n",
    "\n",
    "## and shuffle just in case they are ordered\n",
    "import numpy as np\n",
    "np.random.shuffle(revtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, write a function to generate sentences from reviews that have certain star ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def StarSentences(reviews, stars=[1,2,3,4,5]):\n",
    "    for r in reviews:\n",
    "        if r['y'] in stars:\n",
    "            for s in r['x']:\n",
    "                yield s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit out-of-the-box Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=0, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "\n",
    "## create a w2v learner \n",
    "basemodel = Word2Vec(\n",
    "    workers=multiprocessing.cpu_count(), # use your cores\n",
    "    iter=10) # sweeps of SGD through the data; more is better\n",
    "print basemodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build vocab from all sentences (you could also pre-train the base model from a neutral or un-labeled vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basemodel.build_vocab(StarSentences(revtrain))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will _deep_ copy each base model and do star-specific training. This is where the big computations happen..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 ( 246207 )\n",
      "2 ( 295371 )\n",
      "3 ( 437718 )\n",
      "4 ( 883235 )\n",
      "5 ( 799704 )\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "starmodels = [deepcopy(basemodel) for i in range(5)]\n",
    "for i in range(5):\n",
    "    slist = list(StarSentences(revtrain, [i+1]))\n",
    "    print i+1, \"stars (\", len(slist), \")\"\n",
    "    starmodels[i].train(  slist, total_examples=len(slist) )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inversion of the distributed representations\n",
    "\n",
    "At this point, we have 5 different word2vec language representations.  Each 'model' has been trained conditional (i.e., limited to) text from a specific star rating.  We will apply Bayes rule to go from _p(text|stars)_ to _p(stars|text)_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in the test set\n",
    "revtest = list(YelpReviews(\"test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll go through this step by step for a single review, then give a function at the end to do it all at once.\n",
    "\n",
    "#### step by step example\n",
    "\n",
    "First, for any new sentence we can obtain its _likelihood_ (lhd; actually, the composite likelihood approximation; see the paper) using the [score](https://radimrehurek.com/gensim/models/word2vec.html#gensim.models.word2vec.Word2Vec.score) function in the `word2vec` class.  Here, we get the likelihood for each sentence in the first test review, then convert to a probability over star ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'nice place big patio',\n",
       " u' now offering live sketch comedy ',\n",
       " u' wednesday november 17th see local troupe th sic sense in their 2nd annual holiday show ',\n",
       " u' lighter snappier take on the holiday times',\n",
       " u' not for the easily offended',\n",
       " u' sketches include the scariest holloween costume the first thanksgiving and who shot santa claus ',\n",
       " u' as well as the infectious song mama christmas']"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first review content\n",
    "r = revtest[0]['x']\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1392.73327637, -2621.62890625, -7394.97021484, -3487.50146484,\n",
       "        -2183.92285156, -8392.18261719, -3634.80883789],\n",
       "       [-1330.90319824, -2545.45556641, -7279.16015625, -3442.45458984,\n",
       "        -2109.57788086, -8300.24121094, -3551.42626953],\n",
       "       [-1284.77978516, -2378.11181641, -6906.45703125, -3263.25366211,\n",
       "        -2037.55859375, -7862.79492188, -3409.79345703],\n",
       "       [-1298.27075195, -2346.79321289, -6846.25976562, -3209.80517578,\n",
       "        -1981.15698242, -7657.74462891, -3317.09960938],\n",
       "       [-1309.71130371, -2343.75366211, -6840.29150391, -3190.06494141,\n",
       "        -1954.61560059, -7583.45361328, -3319.27368164]], dtype=float32)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the log likelihood of each sentence in this review under each w2v representation\n",
    "# notice that score() takes a list [s] of sentences\n",
    "llhd = np.array( [ mod.score(r) for mod in starmodels ] )\n",
    "llhd # the 5 x nsentence array of likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 1.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.05,  0.  ,  0.  ,  0.  ,  0.  ,  1.  ],\n",
       "       [ 0.  ,  1.  ,  1.  ,  1.  ,  1.  ,  1.  ,  0.11]], dtype=float32)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now exponentiate to get likelihoods, \n",
    "lhd = np.exp(llhd - llhd.max(axis=0)) # subtract row max to avoid numeric overload\n",
    "lhd.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.05      ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.89999998],\n",
       "       [ 0.        ,  0.94999999,  1.        ,  1.        ,  1.        ,\n",
       "         1.        ,  0.1       ]], dtype=float32)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# divide to get sentence-star probabilities\n",
    "sprob = lhd/lhd.sum(axis=0)\n",
    "sprob.round(2) # mostly 5-star, some 3-4 star sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "star probs:\n",
      "  0.0 0.0 0.14 0.14 0.72 \n",
      "true class is 5\n"
     ]
    }
   ],
   "source": [
    "# and finally average the sentence probabilities to get the review probability\n",
    "rprob = sprob.mean(axis=1)\n",
    "print \"star probs:\\n \",\n",
    "for p in rprob:\n",
    "    print np.round(p,2), \n",
    "print \"\\ntrue class is\", revtest[0]['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### A document probability function\n",
    "\n",
    "Finally, we'll put this all together in a wrapper function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   7.90332334e-43,   0.00000000e+00,\n",
       "          6.32460043e-02,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   5.41475740e-41,\n",
       "          0.00000000e+00,   2.00000003e-01,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   2.00000003e-01,\n",
       "          2.00000003e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.00000003e-01,   0.00000000e+00,\n",
       "          2.00000003e-01,   2.00000003e-01,   0.00000000e+00,\n",
       "          2.00000003e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   7.11641982e-02,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   2.00000003e-01,\n",
       "          2.00000003e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "          2.00000003e-01,   2.00000003e-01,   4.77425256e-20,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   8.01765327e-06,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.00000003e-01,   2.00000003e-01,\n",
       "          2.46126035e-07,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  9.30798394e-21,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.73436771e-32,   0.00000000e+00,\n",
       "          2.23947883e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   1.00309013e-19,\n",
       "          0.00000000e+00,   2.00000003e-01,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   2.00000003e-01,\n",
       "          2.00000003e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.79839303e-42,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.00000003e-01,   0.00000000e+00,\n",
       "          2.00000003e-01,   2.00000003e-01,   1.40129846e-45,\n",
       "          2.00000003e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   8.36197317e-01,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.05386719e-14,   2.00000003e-01,\n",
       "          2.00000003e-01,   2.52886996e-30,   0.00000000e+00,\n",
       "          2.00000003e-01,   2.00000003e-01,   5.24470148e-16,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   6.79238656e-05,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   2.00000003e-01,   2.00000003e-01,\n",
       "          4.61483520e-04,   0.00000000e+00,   2.22972172e-36,\n",
       "          5.31092118e-43,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  9.99998569e-01,   1.14325064e-15,   1.83470722e-29,\n",
       "          1.63886232e-32,   9.51296193e-37,   0.00000000e+00,\n",
       "          4.97517007e-41,   1.76941675e-19,   0.00000000e+00,\n",
       "          9.24000924e-04,   3.51936109e-41,   1.40129846e-45,\n",
       "          1.00859249e-31,   3.72696324e-25,   1.98296152e-06,\n",
       "          4.08499242e-19,   2.00000003e-01,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   2.60062834e-38,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   8.38286875e-37,   0.00000000e+00,\n",
       "          0.00000000e+00,   7.49655210e-21,   2.00000003e-01,\n",
       "          2.00000003e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   6.03109058e-16,   2.18810897e-06,\n",
       "          0.00000000e+00,   3.46120721e-43,   0.00000000e+00,\n",
       "          0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.70359655e-27,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.10916495e-37,   0.00000000e+00,\n",
       "          9.17252111e-17,   2.00000003e-01,   1.12323881e-40,\n",
       "          2.00000003e-01,   2.00000003e-01,   2.86920327e-24,\n",
       "          2.00000003e-01,   0.00000000e+00,   0.00000000e+00,\n",
       "          4.62428493e-44,   1.14967157e-35,   1.23210576e-23,\n",
       "          0.00000000e+00,   0.00000000e+00,   3.30224176e-24,\n",
       "          7.00649232e-45,   0.00000000e+00,   0.00000000e+00,\n",
       "          1.40129846e-45,   1.57784037e-02,   0.00000000e+00,\n",
       "          0.00000000e+00,   1.53852436e-26,   2.00000003e-01,\n",
       "          2.00000003e-01,   2.30228466e-12,   0.00000000e+00,\n",
       "          2.00000003e-01,   2.00000003e-01,   3.18243394e-07,\n",
       "          2.78586094e-27,   0.00000000e+00,   0.00000000e+00,\n",
       "          8.21706960e-13,   0.00000000e+00,   0.00000000e+00,\n",
       "          5.85504948e-28,   4.31003906e-02,   1.50706969e-31,\n",
       "          2.36982296e-16,   0.00000000e+00,   0.00000000e+00,\n",
       "          3.43699472e-32,   2.00000003e-01,   2.00000003e-01,\n",
       "          5.54039329e-03,   0.00000000e+00,   2.72466178e-26,\n",
       "          1.61347660e-27,   0.00000000e+00,   0.00000000e+00,\n",
       "          0.00000000e+00],\n",
       "       [  1.38339738e-06,   4.56707478e-02,   2.55215517e-03,\n",
       "          2.67254574e-09,   2.97320133e-12,   5.44279341e-33,\n",
       "          8.97896886e-01,   1.00000000e+00,   5.67859387e-40,\n",
       "          4.13285106e-01,   1.54549095e-21,   7.32916072e-12,\n",
       "          6.97213096e-08,   1.01497953e-05,   9.99940276e-01,\n",
       "          5.80878073e-19,   2.00000003e-01,   1.00000000e+00,\n",
       "          1.56723364e-19,   1.00000000e+00,   1.00000000e+00,\n",
       "          9.70243633e-30,   0.00000000e+00,   1.61518360e-33,\n",
       "          1.00000000e+00,   9.99999762e-01,   7.35743442e-32,\n",
       "          0.00000000e+00,   5.23301359e-15,   2.00000003e-01,\n",
       "          2.00000003e-01,   0.00000000e+00,   8.48388160e-23,\n",
       "          2.73250488e-37,   1.00000000e+00,   6.47918166e-20,\n",
       "          2.19610737e-29,   1.00000000e+00,   2.41611154e-24,\n",
       "          7.16695504e-18,   0.00000000e+00,   2.63807649e-24,\n",
       "          3.98064703e-02,   4.61380780e-01,   8.56015994e-35,\n",
       "          0.00000000e+00,   5.42886305e-24,   1.50584450e-25,\n",
       "          1.18738352e-09,   2.00000003e-01,   1.34914566e-03,\n",
       "          2.00000003e-01,   2.00000003e-01,   1.00000000e+00,\n",
       "          2.00000003e-01,   7.59503768e-43,   1.00000000e+00,\n",
       "          1.00000000e+00,   9.76524115e-01,   8.25247596e-12,\n",
       "          1.00000000e+00,   0.00000000e+00,   9.17598426e-01,\n",
       "          1.00000000e+00,   9.69207823e-01,   1.00000000e+00,\n",
       "          1.03722883e-07,   2.22994550e-03,   0.00000000e+00,\n",
       "          4.06206174e-24,   9.98792648e-01,   2.00000003e-01,\n",
       "          2.00000003e-01,   1.00000000e+00,   9.99973536e-01,\n",
       "          2.00000003e-01,   2.00000003e-01,   3.48492593e-01,\n",
       "          9.99901056e-01,   6.83707664e-36,   6.12821590e-39,\n",
       "          1.00000000e+00,   1.69529088e-41,   1.00000000e+00,\n",
       "          9.26618045e-16,   3.98279279e-01,   1.46193369e-09,\n",
       "          3.06208494e-05,   4.59848355e-37,   1.00000000e+00,\n",
       "          5.35970275e-06,   2.00000003e-01,   2.00000003e-01,\n",
       "          9.59342301e-01,   1.00000000e+00,   1.00000000e+00,\n",
       "          8.63000170e-19,   9.80756581e-01,   9.79899171e-16,\n",
       "          1.00000000e+00],\n",
       "       [  1.48723117e-11,   9.54329312e-01,   9.97447848e-01,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.02103084e-01,   1.01556766e-11,   1.00000000e+00,\n",
       "          2.98597038e-01,   1.00000000e+00,   1.00000000e+00,\n",
       "          9.99999881e-01,   9.99989867e-01,   5.76683560e-05,\n",
       "          1.00000000e+00,   2.00000003e-01,   3.58164779e-20,\n",
       "          1.00000000e+00,   5.44309823e-13,   3.65308478e-12,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          2.75345653e-12,   2.86842862e-07,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   2.00000003e-01,\n",
       "          2.00000003e-01,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   2.77855415e-15,   9.99997854e-01,\n",
       "          1.00000000e+00,   9.79274576e-17,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          9.60193574e-01,   5.38619220e-01,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.00000000e+00,   1.00000000e+00,\n",
       "          1.00000000e+00,   2.00000003e-01,   9.98650849e-01,\n",
       "          2.00000003e-01,   2.00000003e-01,   7.97657658e-19,\n",
       "          2.00000003e-01,   1.00000000e+00,   1.38849206e-19,\n",
       "          2.60007016e-10,   2.34758481e-02,   1.00000000e+00,\n",
       "          3.25229513e-12,   1.00000000e+00,   8.24014992e-02,\n",
       "          6.57971382e-15,   3.07921674e-02,   5.99430810e-21,\n",
       "          9.99999881e-01,   7.46300966e-02,   1.00000000e+00,\n",
       "          1.00000000e+00,   1.20732549e-03,   2.00000003e-01,\n",
       "          2.00000003e-01,   5.57913524e-12,   2.64162718e-05,\n",
       "          2.00000003e-01,   2.00000003e-01,   6.51507139e-01,\n",
       "          9.89834443e-05,   1.00000000e+00,   1.00000000e+00,\n",
       "          4.57888893e-10,   1.00000000e+00,   1.59455017e-21,\n",
       "          1.00000000e+00,   5.58544338e-01,   1.00000000e+00,\n",
       "          9.99969363e-01,   1.00000000e+00,   8.44714014e-21,\n",
       "          9.99994636e-01,   2.00000003e-01,   2.00000003e-01,\n",
       "          3.46555747e-02,   5.76874106e-13,   6.69693704e-21,\n",
       "          1.00000000e+00,   1.92434732e-02,   1.00000000e+00,\n",
       "          7.67880436e-22]], dtype=float32)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "docprob takes two lists\n",
    "* docs: a list of documents, each of which is a list of sentences\n",
    "* models: the candidate word2vec models (each potential class)\n",
    "\n",
    "it returns the array of class probabilities.  Everything is done in-memory.\n",
    "\"\"\"\n",
    "\n",
    "from itertools import groupby\n",
    "\n",
    "#def docprob(docs, mods):\n",
    "docs = [r['x'] for r in revtest[:10]]\n",
    "mods = starmodels\n",
    "\n",
    "llhd = np.array( [ m.score([s for d in docs for s in d]) for m in mods ] )\n",
    "lhd = np.exp(llhd - llhd.max(axis=0)) # subtract row max to avoid numeric overload\n",
    "prob = lhd/lhd.sum(axis=0)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs\n",
    "a = gensent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'nice place big patio'"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test set example\n",
    "\n",
    "Finally, we'll apply the inversion on the full test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-347-6236f175b774>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrevprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdocprob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstarmodels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrevtest\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-342-f35eed4e1744>\u001b[0m in \u001b[0;36mdocprob\u001b[1;34m(doc, mods)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdocprob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmods\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mllhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmods\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mlhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mllhd\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mllhd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# subtract row max to avoid numeric overload\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlhd\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlhd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/taddy/lib/gensim/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, sentences, total_sentences, chunksize, queue_factor, report_delay)\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0mdone_jobs\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mjob_no\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mpush_done\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 922\u001b[1;33m                     \u001b[0mns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpush_done\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# only block after all jobs pushed\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    923\u001b[0m                     \u001b[0msentence_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m                     \u001b[0mdone_jobs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/anaconda/lib/python2.7/Queue.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    165\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "revprobs = [docprob(r['x'], starmodels) for r in revtest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  0.00000000e+00,   1.32971202e-21,   1.42856941e-01,\n",
       "          1.35160163e-01,   7.21982956e-01], dtype=float32),\n",
       " array([  2.10820008e-02,   7.46492967e-02,   3.08000308e-04,\n",
       "          4.71095055e-01,   4.32865709e-01], dtype=float32),\n",
       " array([  0.00000000e+00,   0.00000000e+00,   9.31741056e-26,\n",
       "          2.55488089e-06,   9.99997497e-01], dtype=float32),\n",
       " array([ 0.02608696,  0.02608696,  0.02608714,  0.33043218,  0.59130675], dtype=float32),\n",
       " array([  0.00000000e+00,   0.00000000e+00,   2.83932750e-28,\n",
       "          1.73301086e-01,   8.26698959e-01], dtype=float32),\n",
       " array([ 0.06153846,  0.06153846,  0.06153846,  0.17405614,  0.64132845], dtype=float32),\n",
       " array([  0.00000000e+00,   0.00000000e+00,   3.83223857e-36,\n",
       "          9.92174685e-01,   7.82528240e-03], dtype=float32),\n",
       " array([  0.00000000e+00,   0.00000000e+00,   4.10701932e-24,\n",
       "          3.33333343e-01,   6.66666687e-01], dtype=float32),\n",
       " array([  0.00000000e+00,   0.00000000e+00,   6.60448352e-25,\n",
       "          7.77361274e-01,   2.22638696e-01], dtype=float32),\n",
       " array([ 0.03852038,  0.06171899,  0.03831574,  0.42084256,  0.44060233], dtype=float32)]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[u'nice', u'place', u'big', u'patio'],\n",
       "  [u'now', u'offering', u'live', u'sketch', u'comedy'],\n",
       "  [u'wednesday',\n",
       "   u'november',\n",
       "   u'17th',\n",
       "   u'see',\n",
       "   u'local',\n",
       "   u'troupe',\n",
       "   u'th',\n",
       "   u'sic',\n",
       "   u'sense',\n",
       "   u'in',\n",
       "   u'their',\n",
       "   u'2nd',\n",
       "   u'annual',\n",
       "   u'holiday',\n",
       "   u'show'],\n",
       "  [u'lighter', u'snappier', u'take', u'on', u'the', u'holiday', u'times'],\n",
       "  [u'not', u'for', u'the', u'easily', u'offended'],\n",
       "  [u'sketches',\n",
       "   u'include',\n",
       "   u'the',\n",
       "   u'scariest',\n",
       "   u'holloween',\n",
       "   u'costume',\n",
       "   u'the',\n",
       "   u'first',\n",
       "   u'thanksgiving',\n",
       "   u'and',\n",
       "   u'who',\n",
       "   u'shot',\n",
       "   u'santa',\n",
       "   u'claus'],\n",
       "  [u'as',\n",
       "   u'well',\n",
       "   u'as',\n",
       "   u'the',\n",
       "   u'infectious',\n",
       "   u'song',\n",
       "   u'mama',\n",
       "   u'christmas']],\n",
       " [[u'friendly', u'staff'],\n",
       "  [u'make',\n",
       "   u'sure',\n",
       "   u'you',\n",
       "   u'order',\n",
       "   u'the',\n",
       "   u'gyro',\n",
       "   u'plate',\n",
       "   u'and',\n",
       "   u'souvlaki',\n",
       "   u'plate'],\n",
       "  [u'yum']],\n",
       " [[u'love', u'love', u'love', u'this', u'place', u'for', u'breakfast'],\n",
       "  [u'they',\n",
       "   u'are',\n",
       "   u'always',\n",
       "   u'busy',\n",
       "   u'but',\n",
       "   u'ive',\n",
       "   u'never',\n",
       "   u'had',\n",
       "   u'to',\n",
       "   u'wait'],\n",
       "  [u'the', u'selection', u'for', u'breakfast', u'is', u'yummy'],\n",
       "  [u'id', u'suggest', u'this', u'place', u'to', u'everyone']],\n",
       " [[u'disgusting', u'sandwich'],\n",
       "  [u'should', u'have', u'known', u'better', u'when', u'the', u'owner'],\n",
       "  [],\n",
       "  [u'told',\n",
       "   u'me',\n",
       "   u'that',\n",
       "   u'they',\n",
       "   u'do',\n",
       "   u'things',\n",
       "   u'different',\n",
       "   u'here',\n",
       "   u'like',\n",
       "   u'cutting',\n",
       "   u'their',\n",
       "   u'rib',\n",
       "   u'eye',\n",
       "   u'pieces',\n",
       "   u'very',\n",
       "   u'thick'],\n",
       "  [u'if',\n",
       "   u'that',\n",
       "   u'isnt',\n",
       "   u'enough',\n",
       "   u'to',\n",
       "   u'send',\n",
       "   u'you',\n",
       "   u'running',\n",
       "   u'if',\n",
       "   u'you',\n",
       "   u'are',\n",
       "   u'loyal',\n",
       "   u'cheesesteak',\n",
       "   u'fan',\n",
       "   u'in',\n",
       "   u'the',\n",
       "   u'know',\n",
       "   u'than',\n",
       "   u'certainly',\n",
       "   u'the',\n",
       "   u'taste',\n",
       "   u'of',\n",
       "   u'the',\n",
       "   u'food',\n",
       "   u'will',\n",
       "   u'get',\n",
       "   u'you',\n",
       "   u'later'],\n",
       "  [u'opened',\n",
       "   u'my',\n",
       "   u'small',\n",
       "   u'makeyour',\n",
       "   u'own',\n",
       "   u'($',\n",
       "   u')',\n",
       "   u'philly',\n",
       "   u'white',\n",
       "   u'american',\n",
       "   u'peppers',\n",
       "   u'onions',\n",
       "   u'and',\n",
       "   u'the',\n",
       "   u'first',\n",
       "   u'thing',\n",
       "   u'saw',\n",
       "   u'was',\n",
       "   u'piece',\n",
       "   u'of',\n",
       "   u'fat',\n",
       "   u'the',\n",
       "   u'size',\n",
       "   u'of',\n",
       "   u'miniice',\n",
       "   u'cube',\n",
       "   u'attached',\n",
       "   u'to',\n",
       "   u'the',\n",
       "   u'steak',\n",
       "   u'which',\n",
       "   u'the',\n",
       "   u'owner',\n",
       "   u'said',\n",
       "   u'they',\n",
       "   u'hand',\n",
       "   u'carve',\n",
       "   u'all',\n",
       "   u'the',\n",
       "   u'time'],\n",
       "  [u'somebody',\n",
       "   u'must',\n",
       "   u'have',\n",
       "   u'been',\n",
       "   u'bit',\n",
       "   u'lazy',\n",
       "   u'and',\n",
       "   u'missed',\n",
       "   u'giant',\n",
       "   u'piece',\n",
       "   u'of',\n",
       "   u'fat'],\n",
       "  [u'chunk',\n",
       "   u'of',\n",
       "   u'fat',\n",
       "   u'that',\n",
       "   u'big',\n",
       "   u'would',\n",
       "   u'not',\n",
       "   u'get',\n",
       "   u'past',\n",
       "   u'even',\n",
       "   u'the',\n",
       "   u'biggest',\n",
       "   u'idiot',\n",
       "   u'cutting',\n",
       "   u'meat'],\n",
       "  [u'the',\n",
       "   u'whole',\n",
       "   u'idea',\n",
       "   u'of',\n",
       "   u'trying',\n",
       "   u'to',\n",
       "   u'do',\n",
       "   u'something',\n",
       "   u'different',\n",
       "   u'with',\n",
       "   u'cheesesteaks',\n",
       "   u'is',\n",
       "   u'nice',\n",
       "   u'but',\n",
       "   u'too',\n",
       "   u'many',\n",
       "   u'folks',\n",
       "   u'well',\n",
       "   u'maybe',\n",
       "   u'not',\n",
       "   u'phoenix',\n",
       "   u'natives',\n",
       "   u'have',\n",
       "   u'specific',\n",
       "   u'standards',\n",
       "   u'for',\n",
       "   u'cheesesteaks',\n",
       "   u'and',\n",
       "   u'you',\n",
       "   u'just',\n",
       "   u'cant',\n",
       "   u'break',\n",
       "   u'these',\n",
       "   u'decades',\n",
       "   u'old',\n",
       "   u'rules',\n",
       "   u'and',\n",
       "   u'create',\n",
       "   u'loyal',\n",
       "   u'following',\n",
       "   u'of',\n",
       "   u'true',\n",
       "   u'fans'],\n",
       "  [u'cut',\n",
       "   u'the',\n",
       "   u'meat',\n",
       "   u'thin',\n",
       "   u'like',\n",
       "   u'every',\n",
       "   u'other',\n",
       "   u'place',\n",
       "   u'in',\n",
       "   u'the',\n",
       "   u'world',\n",
       "   u'and',\n",
       "   u'pay',\n",
       "   u'attention',\n",
       "   u'to',\n",
       "   u'what',\n",
       "   u'your',\n",
       "   u'serving'],\n",
       "  [u'at',\n",
       "   u'least',\n",
       "   u'the',\n",
       "   u'guy',\n",
       "   u'was',\n",
       "   u'nice',\n",
       "   u'when',\n",
       "   u'called',\n",
       "   u'to',\n",
       "   u'inform',\n",
       "   u'him',\n",
       "   u'and',\n",
       "   u'he',\n",
       "   u'told',\n",
       "   u'me',\n",
       "   u'to',\n",
       "   u'come',\n",
       "   u'back',\n",
       "   u'and',\n",
       "   u'make',\n",
       "   u'it',\n",
       "   u'right'],\n",
       "  [u'hold', u'the', u'fat', u'please'],\n",
       "  [u'oh',\n",
       "   u'the',\n",
       "   u'fries',\n",
       "   u'and',\n",
       "   u'onion',\n",
       "   u'rings',\n",
       "   u'are',\n",
       "   u'straight',\n",
       "   u'out',\n",
       "   u'of',\n",
       "   u'the',\n",
       "   u'ole',\n",
       "   u'baggy'],\n",
       "  [u'makes',\n",
       "   u'me',\n",
       "   u'wonder',\n",
       "   u'about',\n",
       "   u'the',\n",
       "   u'ribeye',\n",
       "   u'if',\n",
       "   u'you',\n",
       "   u'cant',\n",
       "   u'cut',\n",
       "   u'your',\n",
       "   u'own',\n",
       "   u'fries',\n",
       "   u'why',\n",
       "   u'would',\n",
       "   u'you',\n",
       "   u'use',\n",
       "   u'the',\n",
       "   u'best',\n",
       "   u'quality',\n",
       "   u'meat'],\n",
       "  [u'they', u'might', u'be', u'cutting', u'corners', u'for', u'profit'],\n",
       "  [],\n",
       "  [],\n",
       "  [u'response',\n",
       "   u'to',\n",
       "   u'owner',\n",
       "   u'the',\n",
       "   u'only',\n",
       "   u'way',\n",
       "   u'to',\n",
       "   u'tarnish',\n",
       "   u'your',\n",
       "   u'restaurants',\n",
       "   u'business',\n",
       "   u'is',\n",
       "   u'to',\n",
       "   u'serve',\n",
       "   u'us',\n",
       "   u'meat',\n",
       "   u'with',\n",
       "   u'fat',\n",
       "   u'chunks',\n",
       "   u'that',\n",
       "   u'you',\n",
       "   u'could',\n",
       "   u'literally',\n",
       "   u'choke',\n",
       "   u'on'],\n",
       "  [u'smart',\n",
       "   u'yelpers',\n",
       "   u'will',\n",
       "   u'realize',\n",
       "   u'that',\n",
       "   u'is',\n",
       "   u'safer',\n",
       "   u'to',\n",
       "   u'eat',\n",
       "   u'your',\n",
       "   u'dinner',\n",
       "   u'out',\n",
       "   u'of',\n",
       "   u'dumpster',\n",
       "   u'than',\n",
       "   u'risk',\n",
       "   u'choking',\n",
       "   u'on',\n",
       "   u'phoenix',\n",
       "   u'fat'],\n",
       "  [u'usda',\n",
       "   u'choice',\n",
       "   u'is',\n",
       "   u'not',\n",
       "   u'the',\n",
       "   u'best',\n",
       "   u'cut',\n",
       "   u'of',\n",
       "   u'rib',\n",
       "   u'eye',\n",
       "   u'it',\n",
       "   u'is',\n",
       "   u'usda',\n",
       "   u'prime',\n",
       "   u'that',\n",
       "   u'is',\n",
       "   u'top',\n",
       "   u'of',\n",
       "   u'the',\n",
       "   u'line'],\n",
       "  [u'certified', u'angus', u'means', u'black', u'hide'],\n",
       "  [u'your', u'considering', u'nonfrozen', u'fries'],\n",
       "  [u'why',\n",
       "   u'thank',\n",
       "   u'you',\n",
       "   u'so',\n",
       "   u'much',\n",
       "   u'for',\n",
       "   u'considering',\n",
       "   u'serving',\n",
       "   u'people',\n",
       "   u'fresh',\n",
       "   u'stuff']],\n",
       " [[u'always',\n",
       "   u'fan',\n",
       "   u'of',\n",
       "   u'cafe',\n",
       "   u'zupas',\n",
       "   u'and',\n",
       "   u'their',\n",
       "   u'very',\n",
       "   u'friendly',\n",
       "   u'staff'],\n",
       "  [u'once',\n",
       "   u'critique',\n",
       "   u'would',\n",
       "   u'be',\n",
       "   u'that',\n",
       "   u'their',\n",
       "   u'soups',\n",
       "   u'tend',\n",
       "   u'to',\n",
       "   u'be',\n",
       "   u'very',\n",
       "   u'salty'],\n",
       "  [u'now',\n",
       "   u'as',\n",
       "   u'for',\n",
       "   u'their',\n",
       "   u'sandwiches',\n",
       "   u'the',\n",
       "   u'turkey',\n",
       "   u'spinach',\n",
       "   u'artichoke',\n",
       "   u'and',\n",
       "   u'pesto',\n",
       "   u'chicken',\n",
       "   u'are',\n",
       "   u'amazing'],\n",
       "  [u'every',\n",
       "   u'time',\n",
       "   u'go',\n",
       "   u'alternate',\n",
       "   u'one',\n",
       "   u'or',\n",
       "   u'the',\n",
       "   u'other',\n",
       "   u'because',\n",
       "   u'theyre',\n",
       "   u'both',\n",
       "   u'so',\n",
       "   u'great'],\n",
       "  [u'the',\n",
       "   u'flavors',\n",
       "   u'for',\n",
       "   u'each',\n",
       "   u'are',\n",
       "   u'so',\n",
       "   u'incredibly',\n",
       "   u'tasty',\n",
       "   u'and',\n",
       "   u'delicious',\n",
       "   u'writing',\n",
       "   u'this',\n",
       "   u'right',\n",
       "   u'now',\n",
       "   u'makes',\n",
       "   u'me',\n",
       "   u'want',\n",
       "   u'to',\n",
       "   u'go',\n",
       "   u'and',\n",
       "   u'get',\n",
       "   u'another',\n",
       "   u'sandwich'],\n",
       "  [u'this', u'place', u'is', u'definitely', u'worth', u'try']],\n",
       " [[u'when',\n",
       "   u'first',\n",
       "   u'get',\n",
       "   u'there',\n",
       "   u'check',\n",
       "   u'the',\n",
       "   u'lot',\n",
       "   u'and',\n",
       "   u'see',\n",
       "   u'the',\n",
       "   u'deals'],\n",
       "  [u'i',\n",
       "   u'get',\n",
       "   u'someone',\n",
       "   u'to',\n",
       "   u'help',\n",
       "   u'and',\n",
       "   u'am',\n",
       "   u'blown',\n",
       "   u'away',\n",
       "   u'on',\n",
       "   u'how',\n",
       "   u'fast',\n",
       "   u'courteous',\n",
       "   u'and',\n",
       "   u'efficient',\n",
       "   u'they',\n",
       "   u'are'],\n",
       "  [u'the',\n",
       "   u'whole',\n",
       "   u'process',\n",
       "   u'felt',\n",
       "   u'like',\n",
       "   u'was',\n",
       "   u'in',\n",
       "   u'control',\n",
       "   u'no',\n",
       "   u'haggle',\n",
       "   u'no',\n",
       "   u'hassle',\n",
       "   u'just',\n",
       "   u'what',\n",
       "   u'wanted',\n",
       "   u'the',\n",
       "   u'car',\n",
       "   u'of',\n",
       "   u'my',\n",
       "   u'dreams'],\n",
       "  [u'absolute', u'love', u'my', u'fiat', u'500', u'pop', u'edition'],\n",
       "  [u'rick',\n",
       "   u'baker',\n",
       "   u'is',\n",
       "   u'the',\n",
       "   u'man',\n",
       "   u'to',\n",
       "   u'see',\n",
       "   u'he',\n",
       "   u'is',\n",
       "   u'very',\n",
       "   u'polite',\n",
       "   u'and',\n",
       "   u'amazing',\n",
       "   u'to',\n",
       "   u'work',\n",
       "   u'with'],\n",
       "  [u'++++++++++++++', u'all', u'the', u'way', u'for', u'this', u'place'],\n",
       "  [],\n",
       "  [u'great',\n",
       "   u'service',\n",
       "   u'friendly',\n",
       "   u'all',\n",
       "   u'the',\n",
       "   u'way',\n",
       "   u'and',\n",
       "   u'you',\n",
       "   u'are',\n",
       "   u'in',\n",
       "   u'control'],\n",
       "  [],\n",
       "  [],\n",
       "  [u'will', u'defiantly', u'buy', u'from', u'again'],\n",
       "  [],\n",
       "  [u'ps',\n",
       "   u'for',\n",
       "   u'every',\n",
       "   u'referral',\n",
       "   u'you',\n",
       "   u'send',\n",
       "   u'you',\n",
       "   u'get',\n",
       "   u'100',\n",
       "   u'what',\n",
       "   u'more',\n",
       "   u'could',\n",
       "   u'you',\n",
       "   u'ask',\n",
       "   u'for']],\n",
       " [[u'great',\n",
       "   u'salsa',\n",
       "   u'especially',\n",
       "   u'if',\n",
       "   u'you',\n",
       "   u'mix',\n",
       "   u'the',\n",
       "   u'red',\n",
       "   u'and',\n",
       "   u'green',\n",
       "   u'together',\n",
       "   u'however',\n",
       "   u'the',\n",
       "   u'chips',\n",
       "   u'are',\n",
       "   u'only',\n",
       "   u'mediocre',\n",
       "   u'very',\n",
       "   u'tasty',\n",
       "   u'refried',\n",
       "   u'beans',\n",
       "   u'amazing',\n",
       "   u'chicken',\n",
       "   u'mole',\n",
       "   u'enchiladas'],\n",
       "  [u'that',\n",
       "   u'little',\n",
       "   u'kick',\n",
       "   u'they',\n",
       "   u'throw',\n",
       "   u'in',\n",
       "   u'is',\n",
       "   u'outstanding',\n",
       "   u'the',\n",
       "   u'enchiladas',\n",
       "   u'suisa',\n",
       "   u'were',\n",
       "   u'amazing'],\n",
       "  [u'great',\n",
       "   u'green',\n",
       "   u'chili',\n",
       "   u'sauce',\n",
       "   u'ill',\n",
       "   u'be',\n",
       "   u'back',\n",
       "   u'to',\n",
       "   u'sample',\n",
       "   u'more',\n",
       "   u'of',\n",
       "   u'menu']],\n",
       " [[u'ajs', u'unsweeted', u'tea', u'selection', u'is', u'amazing'],\n",
       "  [u'with',\n",
       "   u'so',\n",
       "   u'many',\n",
       "   u'flavors',\n",
       "   u'and',\n",
       "   u'healthy',\n",
       "   u'variety',\n",
       "   u'and',\n",
       "   u'all',\n",
       "   u'for',\n",
       "   u'under',\n",
       "   u'2'],\n",
       "  [u'there',\n",
       "   u'is',\n",
       "   u'also',\n",
       "   u'bakery',\n",
       "   u'to',\n",
       "   u'curb',\n",
       "   u'the',\n",
       "   u'sweet',\n",
       "   u'tooth',\n",
       "   u'while',\n",
       "   u'drinking',\n",
       "   u'grean',\n",
       "   u'tea',\n",
       "   u'watermelon',\n",
       "   u'tea',\n",
       "   u'southern',\n",
       "   u'peach',\n",
       "   u'tea',\n",
       "   u'but',\n",
       "   u'my',\n",
       "   u'favorite',\n",
       "   u'tropical',\n",
       "   u'tea']],\n",
       " [[u'i',\n",
       "   u'stop',\n",
       "   u'in',\n",
       "   u'here',\n",
       "   u'from',\n",
       "   u'time',\n",
       "   u'to',\n",
       "   u'time',\n",
       "   u'with',\n",
       "   u'friend',\n",
       "   u'who',\n",
       "   u'lives',\n",
       "   u'locally'],\n",
       "  [u'we',\n",
       "   u'really',\n",
       "   u'enjoy',\n",
       "   u'their',\n",
       "   u'chicken',\n",
       "   u'cobb',\n",
       "   u'salad',\n",
       "   u'and',\n",
       "   u'have',\n",
       "   u'never',\n",
       "   u'ordered',\n",
       "   u'anything',\n",
       "   u'else'],\n",
       "  [u'have',\n",
       "   u'to',\n",
       "   u'say',\n",
       "   u'that',\n",
       "   u'the',\n",
       "   u'people',\n",
       "   u'who',\n",
       "   u'work',\n",
       "   u'here',\n",
       "   u'are',\n",
       "   u'all',\n",
       "   u'very',\n",
       "   u'friendly'],\n",
       "  [u'everyone',\n",
       "   u'greets',\n",
       "   u'you',\n",
       "   u'and',\n",
       "   u'the',\n",
       "   u'atmosphere',\n",
       "   u'is',\n",
       "   u'really',\n",
       "   u'relaxed',\n",
       "   u'and',\n",
       "   u'enjoyable'],\n",
       "  [u'know',\n",
       "   u'this',\n",
       "   u'is',\n",
       "   u'chain',\n",
       "   u'but',\n",
       "   u'this',\n",
       "   u'one',\n",
       "   u'feels',\n",
       "   u'like',\n",
       "   u'local',\n",
       "   u'hangout',\n",
       "   u'with',\n",
       "   u'friendly',\n",
       "   u'people']],\n",
       " [[u'ugh'],\n",
       "  [u'want',\n",
       "   u'to',\n",
       "   u'love',\n",
       "   u'this',\n",
       "   u'place',\n",
       "   u'like',\n",
       "   u'some',\n",
       "   u'of',\n",
       "   u'my',\n",
       "   u'friends',\n",
       "   u'but',\n",
       "   u'going',\n",
       "   u'to',\n",
       "   u'the',\n",
       "   u'original',\n",
       "   u'one',\n",
       "   u'and',\n",
       "   u'waiting',\n",
       "   u'for',\n",
       "   u'hours',\n",
       "   u'just',\n",
       "   u'to',\n",
       "   u'get',\n",
       "   u'some',\n",
       "   u'special',\n",
       "   u'hot',\n",
       "   u'food',\n",
       "   u'has',\n",
       "   u'left',\n",
       "   u'me',\n",
       "   u'feeling',\n",
       "   u'not',\n",
       "   u'positive',\n",
       "   u'for',\n",
       "   u'the',\n",
       "   u'visit',\n",
       "   u'to',\n",
       "   u'this',\n",
       "   u'new',\n",
       "   u'location'],\n",
       "  [u'went',\n",
       "   u'on',\n",
       "   u'wednesday',\n",
       "   u'with',\n",
       "   u'the',\n",
       "   u'mrs',\n",
       "   u'and',\n",
       "   u'friend',\n",
       "   u'that',\n",
       "   u'pushed',\n",
       "   u'me',\n",
       "   u'through',\n",
       "   u'the',\n",
       "   u'door'],\n",
       "  [u'same', u'padres', u'feel'],\n",
       "  [],\n",
       "  [],\n",
       "  [u'was', u'feeling', u'better'],\n",
       "  [u'got',\n",
       "   u'seated',\n",
       "   u'right',\n",
       "   u'away',\n",
       "   u'and',\n",
       "   u'got',\n",
       "   u'chips',\n",
       "   u'and',\n",
       "   u'salsa',\n",
       "   u'and',\n",
       "   u'waters',\n",
       "   u'pretty',\n",
       "   u'quick'],\n",
       "  [],\n",
       "  [],\n",
       "  [u'alright'],\n",
       "  [u'and', u'then', u'we', u'sat', u'and', u'sat', u'and', u'sat'],\n",
       "  [u'we',\n",
       "   u'were',\n",
       "   u'in',\n",
       "   u'little',\n",
       "   u'room',\n",
       "   u'in',\n",
       "   u'the',\n",
       "   u'front',\n",
       "   u'where',\n",
       "   u'the',\n",
       "   u'entrance',\n",
       "   u'to',\n",
       "   u'the',\n",
       "   u'patio',\n",
       "   u'was',\n",
       "   u'and',\n",
       "   u'could',\n",
       "   u'see',\n",
       "   u'all',\n",
       "   u'the',\n",
       "   u'servers',\n",
       "   u'headed',\n",
       "   u'in',\n",
       "   u'and',\n",
       "   u'out',\n",
       "   u'with',\n",
       "   u'drinks',\n",
       "   u'and',\n",
       "   u'food'],\n",
       "  [u'knew', u'it', u'was', u'too', u'good', u'to', u'be', u'true'],\n",
       "  [u'finally',\n",
       "   u'got',\n",
       "   u'drink',\n",
       "   u'order',\n",
       "   u'in',\n",
       "   u'and',\n",
       "   u'he',\n",
       "   u'was',\n",
       "   u'def',\n",
       "   u'hurried'],\n",
       "  [u'no', u'small', u'talk', u'just', u'wanted', u'you', u'to', u'order'],\n",
       "  [u'think', u'the', u'the', u'place', u'was', u'maybe', u'/', u'full'],\n",
       "  [u'got',\n",
       "   u'drinks',\n",
       "   u'and',\n",
       "   u'then',\n",
       "   u'waited',\n",
       "   u'for',\n",
       "   u'about',\n",
       "   u'15',\n",
       "   u'minutes'],\n",
       "  [u'wtf'],\n",
       "  [u'finally', u'ordered', u'with', u'not', u'even', u'eff', u'you'],\n",
       "  [u'from', u'the', u'waiter'],\n",
       "  [u'at',\n",
       "   u'least',\n",
       "   u'it',\n",
       "   u'gave',\n",
       "   u'us',\n",
       "   u'time',\n",
       "   u'to',\n",
       "   u'catch',\n",
       "   u'up',\n",
       "   u'and',\n",
       "   u'take',\n",
       "   u'in',\n",
       "   u'the',\n",
       "   u'decor'],\n",
       "  [u'food', u'came', u'and', u'looked', u'better', u'than', u'remembered'],\n",
       "  [u'but', u'the', u'food', u'was', u'the', u'same'],\n",
       "  [],\n",
       "  [],\n",
       "  [u'meh'],\n",
       "  [u'see', u'other', u'ldm', u'review', u'meh', u'nm', u'style', u'food'],\n",
       "  [u'my', u'family', u'is', u'from', u'nm'],\n",
       "  [u'grew', u'up', u'on', u'the', u'stuff'],\n",
       "  [u'this',\n",
       "   u'is',\n",
       "   u'just',\n",
       "   u'hot',\n",
       "   u'to',\n",
       "   u'tasteless',\n",
       "   u'salty',\n",
       "   u'plate',\n",
       "   u'of',\n",
       "   u'rice',\n",
       "   u'and',\n",
       "   u'beans'],\n",
       "  [u'would', u'come', u'back', u'to', u'have', u'hh', u'at', u'the', u'bar'],\n",
       "  [u'area',\n",
       "   u'at',\n",
       "   u'least',\n",
       "   u'padres',\n",
       "   u'left',\n",
       "   u'that',\n",
       "   u'to',\n",
       "   u'still',\n",
       "   u'be',\n",
       "   u'enjoyed']]]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [[s.split() for s in r['x']] for r in revtest[:10]]\n",
    "docs \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
